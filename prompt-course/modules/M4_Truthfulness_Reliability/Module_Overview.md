# Module 4: Truthfulness & Reliability

> Stop AI from making things up. Get factual, verified output.

## What You'll Learn
This module teaches you to prevent hallucinations, force AI to stay honest, restrict answers to given text, and verify facts.

## Why This Matters
AI can confidently give you wrong answers. If you use false info in a project, exam, or interview - you lose credibility. This module protects you.

## Lessons

| # | Lesson | What You'll Master |
|---|--------|--------------------|
| M4-L1 | "Don't Guess" Mode | Force AI to say "I don't know" instead of guessing |
| M4-L2 | Verification Prompts | Make AI cite sources and check facts |
| M4-L3 | Answer From Given Text Only | Restrict AI to your provided information |
| M4-L4 | Handle Missing Info | Make AI flag gaps instead of inventing data |
| M4-L5 | Anti-Hallucination Checklist | A 5-step checklist to catch false info |

## Key Skill
Trust but verify. After this module, you'll know exactly when AI is reliable and when it's making things up.

## Time to Complete
50-75 minutes (5 lessons x 10-15 min each)

## Student Relevance
- Avoid wrong facts in academic reports
- Verify AI-generated answers before exams
- Build trustworthy project documentation
